{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled13.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMFp41zNptS8QjpRht4exVd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsakailab/iip/blob/main/sandbox/object_detection_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "YGBCfUHIDDvD",
        "outputId": "dfafde80-cdb0-47a0-8731-23371cdc76f5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-064b339f-04eb-40a4-8e8c-a2efecebf863\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-064b339f-04eb-40a4-8e8c-a2efecebf863\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 66 bytes\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHP12_yIDkNt",
        "outputId": "2a65efda-7ba7-4ed0-9f09-fc60f473581e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "ref                                            deadline             category            reward  teamCount  userHasEntered  \n",
            "---------------------------------------------  -------------------  ---------------  ---------  ---------  --------------  \n",
            "contradictory-my-dear-watson                   2030-07-01 23:59:00  Getting Started     Prizes         88           False  \n",
            "gan-getting-started                            2030-07-01 23:59:00  Getting Started     Prizes         76           False  \n",
            "store-sales-time-series-forecasting            2030-06-30 23:59:00  Getting Started  Knowledge        908           False  \n",
            "tpu-getting-started                            2030-06-03 23:59:00  Getting Started  Knowledge        146           False  \n",
            "digit-recognizer                               2030-01-01 00:00:00  Getting Started  Knowledge       1673           False  \n",
            "titanic                                        2030-01-01 00:00:00  Getting Started  Knowledge      14584            True  \n",
            "house-prices-advanced-regression-techniques    2030-01-01 00:00:00  Getting Started  Knowledge       5394           False  \n",
            "connectx                                       2030-01-01 00:00:00  Getting Started  Knowledge        227           False  \n",
            "nlp-getting-started                            2030-01-01 00:00:00  Getting Started  Knowledge        915           False  \n",
            "competitive-data-science-predict-future-sales  2022-12-31 23:59:00  Playground           Kudos      13159           False  \n",
            "tensorflow-great-barrier-reef                  2022-02-14 23:59:00  Research          $150,000        404           False  \n",
            "jigsaw-toxic-severity-rating                   2022-02-07 23:59:00  Featured           $50,000       1001           False  \n",
            "g-research-crypto-forecasting                  2022-02-01 23:59:00  Featured          $125,000        920           False  \n",
            "petfinder-pawpularity-score                    2022-01-13 23:59:00  Research           $25,000       2801           False  \n",
            "santa-2021                                     2022-01-11 23:59:00  Featured           $25,000        669           False  \n",
            "optiver-realized-volatility-prediction         2022-01-10 23:59:00  Featured          $100,000       3852           False  \n",
            "nfl-big-data-bowl-2022                         2022-01-06 23:59:00  Analytics         $100,000          0           False  \n",
            "tabular-playground-series-dec-2021             2021-12-31 23:59:00  Playground            Swag        519           False  \n",
            "sartorius-cell-instance-segmentation           2021-12-30 23:59:00  Featured           $75,000       1266           False  \n",
            "lux-ai-2021                                    2021-12-20 23:59:00  Featured           $10,000       1186           False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download \"andrewmvd/road-sign-detection\" --unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ph7RfVHbDodR",
        "outputId": "4da08eec-8ca4-4715-ff91-21cdc15627ef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading road-sign-detection.zip to /content\n",
            " 95% 208M/218M [00:05<00:00, 45.5MB/s]\n",
            "100% 218M/218M [00:05<00:00, 42.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#library imports\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models"
      ],
      "metadata": {
        "id": "FcK14FycEh9N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "GqsD2BUaExyO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_path = Path('./images')\n",
        "anno_path = Path('./annotations')"
      ],
      "metadata": {
        "id": "sJLgB4SoE4kF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filelist(root, file_type):\n",
        "    \"\"\"Returns a fully-qualified list of filenames under root directory\"\"\"\n",
        "    return [os.path.join(directory_path, f) for directory_path, directory_name, \n",
        "            files in os.walk(root) for f in files if f.endswith(file_type)]\n",
        "\n",
        "def generate_train_df (anno_path):\n",
        "    annotations = filelist(anno_path, '.xml')\n",
        "    anno_list = []\n",
        "    for anno_path in annotations:\n",
        "        root = ET.parse(anno_path).getroot()\n",
        "        anno = {}\n",
        "        anno['filename'] = Path(str(images_path) + '/'+ root.find(\"./filename\").text)\n",
        "        anno['width'] = root.find(\"./size/width\").text\n",
        "        anno['height'] = root.find(\"./size/height\").text\n",
        "        anno['class'] = root.find(\"./object/name\").text\n",
        "        anno['xmin'] = int(root.find(\"./object/bndbox/xmin\").text)\n",
        "        anno['ymin'] = int(root.find(\"./object/bndbox/ymin\").text)\n",
        "        anno['xmax'] = int(root.find(\"./object/bndbox/xmax\").text)\n",
        "        anno['ymax'] = int(root.find(\"./object/bndbox/ymax\").text)\n",
        "        anno_list.append(anno)\n",
        "    return pd.DataFrame(anno_list)"
      ],
      "metadata": {
        "id": "tPiqZxBRE8Q4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = generate_train_df(anno_path)"
      ],
      "metadata": {
        "id": "ZhthCzwME8yr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#label encode target\n",
        "class_dict = {'speedlimit': 0, 'stop': 1, 'crosswalk': 2, 'trafficlight': 3}\n",
        "df_train['class'] = df_train['class'].apply(lambda x:  class_dict[x])"
      ],
      "metadata": {
        "id": "7PXxB8PgE_M1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train.shape)\n",
        "print(len(df_train))\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "_0CZ9bJZFAeD",
        "outputId": "c5f23b73-2adc-47c4-f58f-9ffa571e0721"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(877, 8)\n",
            "877\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>class</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>images/road574.png</td>\n",
              "      <td>300</td>\n",
              "      <td>400</td>\n",
              "      <td>0</td>\n",
              "      <td>86</td>\n",
              "      <td>202</td>\n",
              "      <td>206</td>\n",
              "      <td>327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>images/road481.png</td>\n",
              "      <td>300</td>\n",
              "      <td>400</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>230</td>\n",
              "      <td>144</td>\n",
              "      <td>284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>images/road779.png</td>\n",
              "      <td>300</td>\n",
              "      <td>400</td>\n",
              "      <td>0</td>\n",
              "      <td>68</td>\n",
              "      <td>142</td>\n",
              "      <td>195</td>\n",
              "      <td>269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>images/road649.png</td>\n",
              "      <td>300</td>\n",
              "      <td>400</td>\n",
              "      <td>0</td>\n",
              "      <td>127</td>\n",
              "      <td>155</td>\n",
              "      <td>154</td>\n",
              "      <td>183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>images/road226.png</td>\n",
              "      <td>300</td>\n",
              "      <td>400</td>\n",
              "      <td>0</td>\n",
              "      <td>134</td>\n",
              "      <td>175</td>\n",
              "      <td>156</td>\n",
              "      <td>197</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             filename width height  class  xmin  ymin  xmax  ymax\n",
              "0  images/road574.png   300    400      0    86   202   206   327\n",
              "1  images/road481.png   300    400      0    90   230   144   284\n",
              "2  images/road779.png   300    400      0    68   142   195   269\n",
              "3  images/road649.png   300    400      0   127   155   154   183\n",
              "4  images/road226.png   300    400      0   134   175   156   197"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train.reset_index()"
      ],
      "metadata": {
        "id": "RaTEyTq5FsBc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ljG_gJN7QvuF",
        "outputId": "3a6d2a62-53da-4b0c-b6d8-558eeacd8a9d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>filename</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>class</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>images/road574.png</td>\n",
              "      <td>300</td>\n",
              "      <td>400</td>\n",
              "      <td>0</td>\n",
              "      <td>86</td>\n",
              "      <td>202</td>\n",
              "      <td>206</td>\n",
              "      <td>327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>images/road481.png</td>\n",
              "      <td>300</td>\n",
              "      <td>400</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>230</td>\n",
              "      <td>144</td>\n",
              "      <td>284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>images/road779.png</td>\n",
              "      <td>300</td>\n",
              "      <td>400</td>\n",
              "      <td>0</td>\n",
              "      <td>68</td>\n",
              "      <td>142</td>\n",
              "      <td>195</td>\n",
              "      <td>269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>images/road649.png</td>\n",
              "      <td>300</td>\n",
              "      <td>400</td>\n",
              "      <td>0</td>\n",
              "      <td>127</td>\n",
              "      <td>155</td>\n",
              "      <td>154</td>\n",
              "      <td>183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>images/road226.png</td>\n",
              "      <td>300</td>\n",
              "      <td>400</td>\n",
              "      <td>0</td>\n",
              "      <td>134</td>\n",
              "      <td>175</td>\n",
              "      <td>156</td>\n",
              "      <td>197</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index            filename width height  class  xmin  ymin  xmax  ymax\n",
              "0      0  images/road574.png   300    400      0    86   202   206   327\n",
              "1      1  images/road481.png   300    400      0    90   230   144   284\n",
              "2      2  images/road779.png   300    400      0    68   142   195   269\n",
              "3      3  images/road649.png   300    400      0   127   155   154   183\n",
              "4      4  images/road226.png   300    400      0   134   175   156   197"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_train\n",
        "Y = df_train"
      ],
      "metadata": {
        "id": "-NoWB-6oFsTJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "X_train = X_train.reset_index()\n",
        "X_val = X_val.reset_index()"
      ],
      "metadata": {
        "id": "GHvpqxuxFtcm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "hparam = {'batch_size': 64, 'image_size': (224, 224),\n",
        "          'shuffle': True, 'num_workers': 2,\n",
        "          'mean_color': [0.485, 0.456, 0.406, 0], 'std_color': [0.229, 0.224, 0.225, 1]}\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((400, 300)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.Normalize(hparam['mean_color'], hparam['std_color']),\n",
        "    \n",
        "])\n",
        "\n",
        "class RoadDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "        self.preprocess = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        path = self.dataframe[\"filename\"][idx]\n",
        "        y_class = self.dataframe[\"class\"][idx]\n",
        "        bbox = [self.dataframe[\"xmin\"][idx], self.dataframe[\"ymin\"][idx], self.dataframe[\"xmax\"][idx], self.dataframe[\"ymax\"][idx]]\n",
        "        bbox = torch.tensor(bbox)\n",
        "        out_img = Image.open(path)\n",
        "        out_img = self.preprocess(out_img)\n",
        "        mask = torch.zeros((out_img.shape[1], out_img.shape[2]))\n",
        "        mask[bbox[1]:bbox[3], bbox[0]:bbox[2]] = 1\n",
        "        out_img = torch.cat((out_img[0:3], mask.unsqueeze(0)), 0)\n",
        "        if self.transform:\n",
        "            out_img = self.transform(out_img)\n",
        "        bbox = torch.cat((out_img[-1].nonzero()[:, 1].min().unsqueeze(0), out_img[-1].nonzero()[:, 0].min().unsqueeze(0), out_img[-1].nonzero()[:, 1].max().unsqueeze(0), out_img[-1].nonzero()[:, 0].max().unsqueeze(0)), 0)\n",
        "        return out_img[0:3], y_class, bbox\n",
        "\n",
        "train_ds = RoadDataset(X_train , transform=transform)\n",
        "val_ds = RoadDataset(X_val , transform=transform)"
      ],
      "metadata": {
        "id": "fbP_hgciImEf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_train))\n",
        "print(len(train_ds))\n",
        "print(len(val_ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a_roKGSQzVr",
        "outputId": "3f472416-6f28-4387-e93b-86c4a829dfa0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "877\n",
            "701\n",
            "176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "valid_dl = DataLoader(val_ds, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "aV6_C1ShFy-B"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BB_model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BB_model, self).__init__()\n",
        "        resnet = models.resnet34(pretrained=True)\n",
        "        layers = list(resnet.children())[:8]\n",
        "        self.features1 = nn.Sequential(*layers[:6])\n",
        "        self.features2 = nn.Sequential(*layers[6:])\n",
        "        self.classifier = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n",
        "        self.bb = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.features1(x)\n",
        "        x = self.features2(x)\n",
        "        x = F.relu(x)\n",
        "        x = nn.AdaptiveAvgPool2d((1,1))(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        return self.classifier(x), self.bb(x)"
      ],
      "metadata": {
        "id": "rmxV3RDcF0wI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_optimizer(optimizer, lr):\n",
        "    for i, param_group in enumerate(optimizer.param_groups):\n",
        "        param_group[\"lr\"] = lr"
      ],
      "metadata": {
        "id": "3w2DL91cF6Vd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epocs(model, optimizer, train_dl, val_dl, epochs=10,C=1000):\n",
        "    idx = 0\n",
        "    for i in range(epochs):\n",
        "        model.train()\n",
        "        total = 0\n",
        "        sum_loss = 0\n",
        "        for x, y_class, y_bb in train_dl:\n",
        "            batch = y_class.shape[0]\n",
        "            x = x.cuda().float()\n",
        "            y_class = y_class.cuda()\n",
        "            y_bb = y_bb.cuda().float()\n",
        "            out_class, out_bb = model(x)\n",
        "            loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n",
        "            loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n",
        "            loss_bb = loss_bb.sum()\n",
        "            loss = loss_class + loss_bb/C\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            idx += 1\n",
        "            total += batch\n",
        "            sum_loss += loss.item()\n",
        "        train_loss = sum_loss/total\n",
        "        val_loss, val_acc = val_metrics(model, valid_dl, C)\n",
        "        print(\"train_loss %.3f val_loss %.3f val_acc %.3f\" % (train_loss, val_loss, val_acc))\n",
        "    return sum_loss/total\n"
      ],
      "metadata": {
        "id": "s_702OxUF7e8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val_metrics(model, valid_dl, C=1000):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        total = 0\n",
        "        sum_loss = 0\n",
        "        correct = 0 \n",
        "        for x, y_class, y_bb in valid_dl:\n",
        "            batch = y_class.shape[0]\n",
        "            x = x.cuda().float()\n",
        "            y_class = y_class.cuda()\n",
        "            y_bb = y_bb.cuda().float()\n",
        "            out_class, out_bb = model(x)\n",
        "            loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n",
        "            loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n",
        "            loss_bb = loss_bb.sum()\n",
        "            loss = loss_class + loss_bb/C\n",
        "            _, pred = torch.max(out_class, 1)\n",
        "            correct += pred.eq(y_class).sum().item()\n",
        "            sum_loss += loss.item()\n",
        "            total += batch\n",
        "    return sum_loss/total, correct/total"
      ],
      "metadata": {
        "id": "LeI3Pxp6F9LR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BB_model().cuda()\n",
        "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "optimizer = torch.optim.Adam(parameters, lr=0.006)"
      ],
      "metadata": {
        "id": "k78Oel-ZF-j3"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "        # return out_img[0:3], y_class, bbox\n",
        "        \n",
        "def train_epocs(model, optimizer, train_dl, val_dl, epochs=10,C=1000):\n",
        "    idx = 0\n",
        "    for i in range(epochs):\n",
        "        model.train()\n",
        "        total = 0\n",
        "        sum_loss = 0\n",
        "        for x, y_class, y_bb in train_dl:\n",
        "            batch = y_class.shape[0]\n",
        "            x = x.cuda().float()\n",
        "            y_class = y_class.cuda()\n",
        "            y_bb = y_bb.cuda().float()\n",
        "            out_class, out_bb = model(x)\n",
        "            loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n",
        "            loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n",
        "            loss_bb = loss_bb.sum()\n",
        "            loss = loss_class + loss_bb/C\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            idx += 1\n",
        "            total += batch\n",
        "            sum_loss += loss.item()\n",
        "        train_loss = sum_loss/total\n",
        "        val_loss, val_acc = val_metrics(model, valid_dl, C)\n",
        "        print(\"train_loss %.3f val_loss %.3f val_acc %.3f\" % (train_loss, val_loss, val_acc))\n",
        "    return sum_loss/total\n",
        "\n",
        "train_epocs(model, optimizer, train_dl, valid_dl, epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftz-V9RJF_5L",
        "outputId": "47afcb08-1a66-4033-d628-0befad0af54c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss 2.610 val_loss 9283.244 val_acc 0.080\n",
            "train_loss 1.819 val_loss 307.220 val_acc 0.324\n",
            "train_loss 1.557 val_loss 43.103 val_acc 0.341\n",
            "train_loss 1.304 val_loss 7.262 val_acc 0.699\n",
            "train_loss 1.234 val_loss 1.573 val_acc 0.744\n",
            "train_loss 1.122 val_loss 2.110 val_acc 0.761\n",
            "train_loss 1.094 val_loss 3.063 val_acc 0.494\n",
            "train_loss 0.994 val_loss 1.040 val_acc 0.773\n",
            "train_loss 0.943 val_loss 0.770 val_acc 0.795\n",
            "train_loss 0.864 val_loss 0.753 val_acc 0.778\n",
            "train_loss 0.859 val_loss 0.818 val_acc 0.790\n",
            "train_loss 0.875 val_loss 0.714 val_acc 0.818\n",
            "train_loss 0.863 val_loss 0.839 val_acc 0.824\n",
            "train_loss 0.853 val_loss 0.885 val_acc 0.784\n",
            "train_loss 0.878 val_loss 0.870 val_acc 0.750\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8784324167118263"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_optimizer(optimizer, 0.001)\n",
        "train_epocs(model, optimizer, train_dl, valid_dl, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw9FiuOiGSHa",
        "outputId": "f3f98761-e86b-4b8e-bdb8-2b45e7d06b07"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss 0.838 val_loss 0.681 val_acc 0.807\n",
            "train_loss 0.789 val_loss 0.675 val_acc 0.801\n",
            "train_loss 0.799 val_loss 0.676 val_acc 0.812\n",
            "train_loss 0.762 val_loss 0.661 val_acc 0.801\n",
            "train_loss 0.763 val_loss 0.655 val_acc 0.790\n",
            "train_loss 0.752 val_loss 0.667 val_acc 0.807\n",
            "train_loss 0.753 val_loss 0.659 val_acc 0.812\n",
            "train_loss 0.738 val_loss 0.637 val_acc 0.812\n",
            "train_loss 0.754 val_loss 0.636 val_acc 0.818\n",
            "train_loss 0.738 val_loss 0.639 val_acc 0.812\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7376027127645495"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# choose random image from validation set\n",
        "X_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "4Ld5Sy53GZWQ",
        "outputId": "06609661-772a-48ff-a74e-5b2eea43ca84"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level_0</th>\n",
              "      <th>index</th>\n",
              "      <th>filename</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>class</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>710</td>\n",
              "      <td>710</td>\n",
              "      <td>images/road221.png</td>\n",
              "      <td>300</td>\n",
              "      <td>400</td>\n",
              "      <td>0</td>\n",
              "      <td>131</td>\n",
              "      <td>185</td>\n",
              "      <td>154</td>\n",
              "      <td>208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>734</td>\n",
              "      <td>734</td>\n",
              "      <td>images/road766.png</td>\n",
              "      <td>300</td>\n",
              "      <td>400</td>\n",
              "      <td>0</td>\n",
              "      <td>134</td>\n",
              "      <td>188</td>\n",
              "      <td>174</td>\n",
              "      <td>227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>244</td>\n",
              "      <td>244</td>\n",
              "      <td>images/road107.png</td>\n",
              "      <td>320</td>\n",
              "      <td>400</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>37</td>\n",
              "      <td>233</td>\n",
              "      <td>232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>231</td>\n",
              "      <td>231</td>\n",
              "      <td>images/road58.png</td>\n",
              "      <td>400</td>\n",
              "      <td>301</td>\n",
              "      <td>1</td>\n",
              "      <td>58</td>\n",
              "      <td>24</td>\n",
              "      <td>331</td>\n",
              "      <td>295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>291</td>\n",
              "      <td>291</td>\n",
              "      <td>images/road788.png</td>\n",
              "      <td>300</td>\n",
              "      <td>400</td>\n",
              "      <td>0</td>\n",
              "      <td>106</td>\n",
              "      <td>147</td>\n",
              "      <td>149</td>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>images/road444.png</td>\n",
              "      <td>300</td>\n",
              "      <td>400</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>122</td>\n",
              "      <td>190</td>\n",
              "      <td>166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>215</td>\n",
              "      <td>215</td>\n",
              "      <td>images/road249.png</td>\n",
              "      <td>300</td>\n",
              "      <td>400</td>\n",
              "      <td>0</td>\n",
              "      <td>145</td>\n",
              "      <td>239</td>\n",
              "      <td>156</td>\n",
              "      <td>251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>350</td>\n",
              "      <td>350</td>\n",
              "      <td>images/road158.png</td>\n",
              "      <td>300</td>\n",
              "      <td>400</td>\n",
              "      <td>2</td>\n",
              "      <td>168</td>\n",
              "      <td>112</td>\n",
              "      <td>225</td>\n",
              "      <td>170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>81</td>\n",
              "      <td>81</td>\n",
              "      <td>images/road634.png</td>\n",
              "      <td>300</td>\n",
              "      <td>400</td>\n",
              "      <td>1</td>\n",
              "      <td>123</td>\n",
              "      <td>83</td>\n",
              "      <td>168</td>\n",
              "      <td>128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>677</td>\n",
              "      <td>677</td>\n",
              "      <td>images/road810.png</td>\n",
              "      <td>300</td>\n",
              "      <td>400</td>\n",
              "      <td>0</td>\n",
              "      <td>129</td>\n",
              "      <td>175</td>\n",
              "      <td>169</td>\n",
              "      <td>215</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>176 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     level_0  index            filename width  ... xmin  ymin  xmax  ymax\n",
              "0        710    710  images/road221.png   300  ...  131   185   154   208\n",
              "1        734    734  images/road766.png   300  ...  134   188   174   227\n",
              "2        244    244  images/road107.png   320  ...   90    37   233   232\n",
              "3        231    231   images/road58.png   400  ...   58    24   331   295\n",
              "4        291    291  images/road788.png   300  ...  106   147   149   190\n",
              "..       ...    ...                 ...   ...  ...  ...   ...   ...   ...\n",
              "171      500    500  images/road444.png   300  ...  146   122   190   166\n",
              "172      215    215  images/road249.png   300  ...  145   239   156   251\n",
              "173      350    350  images/road158.png   300  ...  168   112   225   170\n",
              "174       81     81  images/road634.png   300  ...  123    83   168   128\n",
              "175      677    677  images/road810.png   300  ...  129   175   169   215\n",
              "\n",
              "[176 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# resizing test image\n",
        "im = read_image('./road_signs/images_resized/road789.png')\n",
        "im = cv2.resize(im, (int(1.49*300), 300))\n",
        "cv2.imwrite('./road_signs/road_signs_test/road789.jpg', cv2.cvtColor(im, cv2.COLOR_RGB2BGR))"
      ],
      "metadata": {
        "id": "WK6AG0DJGawR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test Dataset\n",
        "test_ds = RoadDataset(pd.DataFrame([{'path':'./road_signs/road_signs_test/road789.jpg'}])['path'],pd.DataFrame([{'bb':np.array([0,0,0,0])}])['bb'],pd.DataFrame([{'y':[0]}])['y'])\n",
        "x, y_class, y_bb = test_ds[0]"
      ],
      "metadata": {
        "id": "KFzc60n9GclW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xx = torch.FloatTensor(x[None,])\n",
        "xx.shape"
      ],
      "metadata": {
        "id": "SgeT_ap9GeFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "out_class, out_bb = model(xx.cuda())\n",
        "out_class, out_bb"
      ],
      "metadata": {
        "id": "9Nsp4-3jGfUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicted class\n",
        "torch.max(out_class, 1)"
      ],
      "metadata": {
        "id": "yTlrEsKfGgoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicted bounding box\n",
        "bb_hat = out_bb.detach().cpu().numpy()\n",
        "bb_hat = bb_hat.astype(int)\n",
        "show_corner_bb(im, bb_hat[0])"
      ],
      "metadata": {
        "id": "F34bEMp2Gh5Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}