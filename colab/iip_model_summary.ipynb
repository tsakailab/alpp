{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iip_model_summary.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1Tek8K_mfHhO",
        "2jRBm49N462k"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsakailab/iip/blob/main/colab/iip_model_summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQdBd12euPZX"
      },
      "source": [
        "# 画像認識のCNNモデルの構造を覗いてみよう\n",
        "\n",
        "画像認識のニューラルネットワークは，局所的な特徴（断片的な形状，模様，配色）の組合せを調べるため，畳み込み層，活性化層，プーリング層，全結合層などの部品から構成されています．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Tek8K_mfHhO"
      },
      "source": [
        "## 学習済みのCNNモデルをTorchvisionから入手します．\n",
        "\n",
        "[The pre-trained models have been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.](https://pytorch.org/vision/stable/models.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irfdbJZ3aSRq"
      },
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "\n",
        "model = models.alexnet(pretrained=True)\n",
        "#model = models.vgg16(pretrained=True)\n",
        "#model = models.vgg16_bn(pretrained=True)\n",
        "#model = models.resnet50(pretrained=True)\n",
        "#model = models.googlenet(pretrained=True)\n",
        "#model = models.mobilenet_v3_small(pretrained=True)\n",
        "#model = models.efficientnet_b0(pretrained=True)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxM9uiu-h0QF"
      },
      "source": [
        "### torch.nn.Moduleで構成されたモデルはprintで表示できます．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CLK3N2GfToZ"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jna-uxZEhgUE"
      },
      "source": [
        "### 各層の**特徴マップ（feature maps）**のサイズと**学習可能なパラメタ（trainable parameters）**の数を**torchsummary**で表示します．\n",
        "\n",
        "注：input_sizeは，想定する入力画像のサイズです（例：vgg16やalexnetでは32以上）．モデルによって，AdaptiveAvgPool2dまたはAdaptiveMaxpool2dで強制的に所定の大きさになります（vgg16では[-1,512,7,7]，alexnetでは[-1,256,6,6]）．\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlEzPq3Eg-fw"
      },
      "source": [
        "from torchsummary import summary\n",
        "input_size=224\n",
        "summary(model, (3, input_size, input_size), device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jRBm49N462k"
      },
      "source": [
        "## 学習済みのモデルを[PyTorch Hub](https://pytorch.org/hub/research-models)からも入手できます．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT-E5n8c47E0"
      },
      "source": [
        "import torch\n",
        "\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
        "#model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16_bn', pretrained=True) #vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, vgg19_bn\n",
        "#model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True) # resnet18, resnet34, resnet50, resnet101, resnet152\n",
        "#model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n",
        "#model = torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', pretrained=True)\n",
        "#model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50')\n",
        "#model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet', type='efficientnet-widese-b0')\n",
        "#model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd')\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ocba9hi5YHP"
      },
      "source": [
        "from torchsummary import summary\n",
        "input_size=300\n",
        "summary(model, (3, input_size, input_size), device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llPAqoTK4eJ6"
      },
      "source": [
        "# 参考資料\n",
        "[VGG](https://arxiv.org/abs/1409.1556)\n",
        "[ResNet](https://arxiv.org/abs/1512.03385)\n",
        "[Inception](https://arxiv.org/abs/1512.00567)\n",
        "[GoogLeNet](https://arxiv.org/abs/1409.4842)\n",
        "[その他](https://www.topbots.com/important-cnn-architectures/)\n",
        "\n",
        "![](https://www.researchgate.net/profile/Evgeny-Baraboshkin/publication/335989937/figure/fig3/AS:806501341999104@1569296312136/Neural-networks-architecture-simplified-sketches-inception-and-residual-modules.png)\n",
        "Neural networks architecture simplified sketches, inception and residual modules structures can be observed in the detailed network maps in online repository (\"Supplementary materials to the article,\" n.d.). 0 -convolutoion layer, 1 -activation layer, 2 -Inception module, 3 -average pooling, 4 -batch normalization, 5 -max pooling, 6 -zero padding, 7 -Residual module, 8 -drop out layer, 9 -layer composition, 10 -dense layer.\n",
        "\n",
        "\n",
        "![](https://drek4537l1klr.cloudfront.net/elgendy/v-3/Figures/05_27.png)\n",
        "![](https://i.ytimg.com/vi/VxhSouuSZDY/maxresdefault.jpg)\n",
        "\n"
      ]
    }
  ]
}