{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsakailab/alpp/blob/main/colab/demo_CLIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLIP (Contrastive Language-Image Pre-training)\n",
        "<img src=\"https://images.openai.com/blob/fbc4f633-9ad4-4dc2-bd94-0b6f1feee22f/overview-a.svg?width=10&height=10&quality=50\" width=480 align=\"top\" /> &emsp;&emsp;\n",
        "<img src=\"https://images.openai.com/blob/d9d46e4b-6d6a-4f9e-9345-5c6538b1b8c3/overview-b.svg?width=10&height=10&quality=50\" width=480 align=\"top\" style=\"float:left\"/>\n",
        "\n",
        "## CLIPを試食しましょう．\n",
        "\n",
        "----\n",
        "### CLIPをインストールして，学習済みのモデルを入手します．\n",
        "ダウンロードに1分程度時間がかかります．"
      ],
      "metadata": {
        "id": "QFqnXFmwCvK9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkXYDlATDtQv"
      },
      "outputs": [],
      "source": [
        "!pip install -q open_clip_torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import open_clip\n",
        "model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')\n",
        "tokenizer = open_clip.get_tokenizer('ViT-B-32')\n",
        "model.eval();"
      ],
      "metadata": {
        "id": "QuhTlhC9vROw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Web上の画像を取得して表示します．"
      ],
      "metadata": {
        "id": "qlP_83bXDFOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uri = \"http://static.independent.co.uk/s3fs-public/styles/article_large/public/thumbnails/image/2016/02/25/13/cat-getty_0.jpg\"\n",
        "\n",
        "import imageio.v3 as imageio\n",
        "cimg = imageio.imread(uri)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(cimg); plt.axis('off');"
      ],
      "metadata": {
        "id": "2wOkdLvjvrnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 画像を英語で記述します．\n",
        "- 文の数や長さは自由です（下の例では6つの文を用意しました）"
      ],
      "metadata": {
        "id": "Um0MItiJDaEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    \"A photo of a cute cat.\",\n",
        "    \"This small orange kitten melts hearts with its adorable expression as it gazes into the camera's lens.\",\n",
        "    \"This small orange tiger melts hearts with its adorable expression as it gazes into the camera's lens.\",\n",
        "    \"A tiny orange kitten has perfected the art of capturing attention with its captivating stare. \",\n",
        "    \"Twin kittens\",\n",
        "    \"Captivating cityscape, where modern skyscrapers and bustling streets blend in perfect harmony.\",\n",
        "    ]"
      ],
      "metadata": {
        "id": "kkU0n0wKCkNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 画像と各文の類似度を評価し，下記の値を表示します．\n",
        "- コサイン類似度\n",
        "- softmax関数で換算した確率"
      ],
      "metadata": {
        "id": "5f0yxJYOGe6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image = preprocess(Image.fromarray(cimg)).unsqueeze(0)\n",
        "image_features = model.encode_image(image)\n",
        "\n",
        "text = tokenizer(texts)\n",
        "text_features = model.encode_text(text)\n",
        "\n",
        "unit_image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "unit_text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "similarities = unit_image_features.matmul(unit_text_features.T)\n",
        "text_probs = (100.0 * similarities).softmax(dim=-1)\n",
        "\n",
        "print(*[\"{:>+.3f} ({:6.1%} )\".format(cossim, prob.item()) + \": \\\"\"\n",
        "        + (txt[:80]+\"...\\\"\" if len(txt)>80 else txt+\"\\\"\"+\" \"*(83-len(txt))) + \" ({:d} tokens)\".format(ntok)\n",
        "        for cossim, prob, txt, ntok in zip(*similarities, *text_probs.data, texts, text.count_nonzero(dim=1))], sep='\\n')"
      ],
      "metadata": {
        "id": "5FxTfm8BDt6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## さあ，あなたの番です．\n",
        "### 画像を取得して表示します．"
      ],
      "metadata": {
        "id": "tXFjApKDI4f6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uri = \"https://cdn.cms-twdigitalassets.com/content/dam/help-twitter/ja/using-twitter/accessibility/write-image-desc/1_Succinct_clear_detailed_example.jpeg.twimg.1920.jpeg\"\n",
        "#uri = \"https://github.com/pytorch/hub/raw/master/images/dog.jpg\"\n",
        "#uri = \"https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F166345%2F7358a513-a377-c29f-2a3d-4e2058990576.jpeg?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=6946b0bc6140a739bc60ddaa3a0aab8c\"\n",
        "#uri = \"http://images.cocodataset.org/test-stuff2017/000000006149.jpg\"\n",
        "#uri = \"http://images.cocodataset.org/test-stuff2017/000000024309.jpg\"\n",
        "#uri = \"http://images.cocodataset.org/test-stuff2017/000000004954.jpg\"\n",
        "#uri = \"https://otamatone.jp/cms/wp-content/uploads/2019/09/190421_otamatone71638-300x300.jpg\"\n",
        "#uri = \"https://eeo.today/media/wp-content/uploads/2024/01/17171601/15.png\"\n",
        "\n",
        "cimg = imageio.imread(uri, pilmode='RGBA')[:,:,:3]\n",
        "plt.imshow(cimg); plt.axis('off');"
      ],
      "metadata": {
        "id": "CKVvWXQPCtDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 画像を英語で記述してください．\n",
        "- 文の数や長さは自由です．\n",
        "- 翻訳で作文してもよいです　→　[DeepL](https://www.deepl.com/ja/translator)"
      ],
      "metadata": {
        "id": "6IgNAi4GGSJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    \"A photo of X\",\n",
        "    \"Verbalize the picture yourself.\",\n",
        "    \"\",\n",
        "    ]"
      ],
      "metadata": {
        "id": "_eLKIzpcJeXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = preprocess(Image.fromarray(cimg)).unsqueeze(0)\n",
        "image_features = model.encode_image(image)\n",
        "\n",
        "text = tokenizer(texts)\n",
        "text_features = model.encode_text(text)\n",
        "\n",
        "unit_image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "unit_text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "similarities = unit_image_features.matmul(unit_text_features.T)\n",
        "text_probs = (100.0 * similarities).softmax(dim=-1)\n",
        "\n",
        "print(*[\"{:>+.3f} ({:6.1%} )\".format(cossim, prob.item()) + \": \\\"\"\n",
        "        + (txt[:80]+\"...\\\"\" if len(txt)>80 else txt+\"\\\"\"+\" \"*(83-len(txt))) + \" ({:2d} tokens)\".format(ntok)\n",
        "        for cossim, prob, txt, ntok in zip(*similarities, *text_probs.data, texts, text.count_nonzero(dim=1))], sep='\\n')"
      ],
      "metadata": {
        "id": "57AcvIDKKXTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 参考：画像とテキストとの間の変換技術\n",
        "画像や図の題を自動的に生成する技術は[image captioning](https://paperswithcode.com/task/image-captioning)と呼ばれています．\n",
        "- [huggingface.co](https://huggingface.co/docs/transformers/main/en/tasks/image_captioning) [paperwithcode.com](https://paperswithcode.com/task/image-captioning)\n",
        "- [試食する1](https://huggingface.co/spaces/SRDdev/Image-Caption), [試食する2](ttps://imagecaptiongenerator.com/)\n",
        "\n",
        "逆に，テキストから画像を生成する技術が[text-to-image generation](https://en.wikipedia.org/wiki/Text-to-image_model)であり，[stable diffusion](https://en.wikipedia.org/wiki/Stable_Diffusion)等が有名です．\n",
        "\n",
        "<br>\n",
        "\n",
        "# 参考：あなた自身の言語化能力を伸ばすための教材\n",
        "視覚情報を言語化する能力の育成は，情報リテラシー教育の盲点です．\n",
        "- [良い画像の説明を作成する方法（How to write great image descriptions）](https://help.twitter.com/ja/using-x/write-image-descriptions)\n",
        "- [Image Description Guidelines](http://diagramcenter.org/table-of-contents-2.html)\n",
        "- [Effective Practices for Description of Science Content within Digital Talking Books](https://www.wgbh.org/foundation/services/ncam/effective-practices-for-description-of-science-content-within-digital-talking-books)\n",
        "- [Describing Figures](https://www.sigaccess.org/welcome-to-sigaccess/resources/describing-figures/)"
      ],
      "metadata": {
        "id": "noqntpoDztIp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "# 以下，おまけ（[参考](https://github.com/mlfoundations/open_clip/blob/main/docs/Interacting_with_open_clip.ipynb)）"
      ],
      "metadata": {
        "id": "QvZwc1_geej-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = model.context_length\n",
        "vocab_size = model.vocab_size\n",
        "\n",
        "import numpy as np\n",
        "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
        "print(\"Context length:\", context_length)\n",
        "print(\"Vocab size:\", vocab_size)"
      ],
      "metadata": {
        "id": "GngGB0vAmLtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabs = tokenizer.encoder\n",
        "print(len(vocabs))\n",
        "import random\n",
        "print(*random.sample(list(vocabs.items()), 5), sep='  ')"
      ],
      "metadata": {
        "id": "O7Sncfn6ec6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text.count_nonzero(dim=1))\n",
        "print(*texts, sep='\\n')\n",
        "print(text)"
      ],
      "metadata": {
        "id": "kZaCKxklghu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import open_clip\n",
        "open_clip.list_pretrained()"
      ],
      "metadata": {
        "id": "tMVWQwLVKfMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess"
      ],
      "metadata": {
        "id": "1hd__K5jHq7B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}